{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\lib'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### from segmentted text file to utilize word2vec\n",
    "import os\n",
    "os.path.dirname(os.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-27 10:29:12,025 : INFO : collecting all words and their counts\n",
      "2018-06-27 10:29:12,031 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-06-27 10:29:16,998 : INFO : collected 204977 word types from a corpus of 9860127 raw words and 987 sentences\n",
      "2018-06-27 10:29:16,999 : INFO : Loading a fresh vocabulary\n",
      "2018-06-27 10:29:17,266 : INFO : min_count=5 retains 56329 unique words (27% of original 204977, drops 148648)\n",
      "2018-06-27 10:29:17,267 : INFO : min_count=5 leaves 9629795 word corpus (97% of original 9860127, drops 230332)\n",
      "2018-06-27 10:29:17,505 : INFO : deleting the raw counts dictionary of 204977 items\n",
      "2018-06-27 10:29:17,516 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2018-06-27 10:29:17,517 : INFO : downsampling leaves estimated 7557112 word corpus (78.5% of prior 9629795)\n",
      "2018-06-27 10:29:17,767 : INFO : estimated required memory for 56329 words and 200 dimensions: 118290900 bytes\n",
      "2018-06-27 10:29:17,768 : INFO : resetting layer weights\n",
      "2018-06-27 10:29:18,740 : INFO : training model with 3 workers on 56329 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-06-27 10:29:19,764 : INFO : EPOCH 1 - PROGRESS: at 6.69% examples, 496650 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:20,797 : INFO : EPOCH 1 - PROGRESS: at 13.58% examples, 501796 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:29:21,807 : INFO : EPOCH 1 - PROGRESS: at 20.57% examples, 509117 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:22,809 : INFO : EPOCH 1 - PROGRESS: at 27.76% examples, 517686 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:23,816 : INFO : EPOCH 1 - PROGRESS: at 33.54% examples, 501541 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:24,820 : INFO : EPOCH 1 - PROGRESS: at 40.22% examples, 502068 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:25,835 : INFO : EPOCH 1 - PROGRESS: at 47.42% examples, 507400 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:26,855 : INFO : EPOCH 1 - PROGRESS: at 53.39% examples, 499564 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:27,864 : INFO : EPOCH 1 - PROGRESS: at 58.87% examples, 489745 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:28,880 : INFO : EPOCH 1 - PROGRESS: at 64.64% examples, 483799 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:29,883 : INFO : EPOCH 1 - PROGRESS: at 71.02% examples, 482748 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:30,887 : INFO : EPOCH 1 - PROGRESS: at 77.51% examples, 482799 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:31,900 : INFO : EPOCH 1 - PROGRESS: at 83.79% examples, 481791 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:32,901 : INFO : EPOCH 1 - PROGRESS: at 90.07% examples, 481324 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:33,905 : INFO : EPOCH 1 - PROGRESS: at 96.15% examples, 479749 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:34,454 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-27 10:29:34,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 10:29:34,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 10:29:34,470 : INFO : EPOCH - 1 : training on 9860127 raw words (7556962 effective words) took 15.7s, 480512 effective words/s\n",
      "2018-06-27 10:29:35,485 : INFO : EPOCH 2 - PROGRESS: at 6.08% examples, 456117 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:36,488 : INFO : EPOCH 2 - PROGRESS: at 12.66% examples, 477555 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:37,493 : INFO : EPOCH 2 - PROGRESS: at 18.84% examples, 473689 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:38,509 : INFO : EPOCH 2 - PROGRESS: at 25.13% examples, 472410 words/s, in_qsize 4, out_qsize 2\n",
      "2018-06-27 10:29:39,527 : INFO : EPOCH 2 - PROGRESS: at 31.21% examples, 468474 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:40,546 : INFO : EPOCH 2 - PROGRESS: at 37.69% examples, 470925 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:29:41,560 : INFO : EPOCH 2 - PROGRESS: at 44.07% examples, 471988 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:29:42,587 : INFO : EPOCH 2 - PROGRESS: at 50.66% examples, 473811 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:43,597 : INFO : EPOCH 2 - PROGRESS: at 56.94% examples, 473688 words/s, in_qsize 4, out_qsize 0\n",
      "2018-06-27 10:29:44,598 : INFO : EPOCH 2 - PROGRESS: at 63.22% examples, 473789 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:45,629 : INFO : EPOCH 2 - PROGRESS: at 69.50% examples, 472036 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:46,649 : INFO : EPOCH 2 - PROGRESS: at 76.09% examples, 472753 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:47,651 : INFO : EPOCH 2 - PROGRESS: at 81.86% examples, 470030 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:48,652 : INFO : EPOCH 2 - PROGRESS: at 88.25% examples, 470931 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:49,666 : INFO : EPOCH 2 - PROGRESS: at 94.73% examples, 471764 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:50,418 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-27 10:29:50,428 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 10:29:50,446 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 10:29:50,449 : INFO : EPOCH - 2 : training on 9860127 raw words (7557515 effective words) took 16.0s, 473075 effective words/s\n",
      "2018-06-27 10:29:51,469 : INFO : EPOCH 3 - PROGRESS: at 5.88% examples, 443632 words/s, in_qsize 4, out_qsize 1\n",
      "2018-06-27 10:29:52,471 : INFO : EPOCH 3 - PROGRESS: at 12.36% examples, 467213 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:53,504 : INFO : EPOCH 3 - PROGRESS: at 18.95% examples, 472638 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:29:54,546 : INFO : EPOCH 3 - PROGRESS: at 24.92% examples, 462983 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:29:55,564 : INFO : EPOCH 3 - PROGRESS: at 31.21% examples, 463970 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:56,577 : INFO : EPOCH 3 - PROGRESS: at 37.39% examples, 463785 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:57,586 : INFO : EPOCH 3 - PROGRESS: at 43.77% examples, 466297 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:29:58,590 : INFO : EPOCH 3 - PROGRESS: at 50.25% examples, 469246 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:29:59,591 : INFO : EPOCH 3 - PROGRESS: at 56.23% examples, 467476 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:00,605 : INFO : EPOCH 3 - PROGRESS: at 61.80% examples, 462335 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:01,608 : INFO : EPOCH 3 - PROGRESS: at 67.58% examples, 459692 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:02,614 : INFO : EPOCH 3 - PROGRESS: at 73.96% examples, 460397 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:03,617 : INFO : EPOCH 3 - PROGRESS: at 79.94% examples, 459688 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:04,644 : INFO : EPOCH 3 - PROGRESS: at 86.42% examples, 461018 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:05,664 : INFO : EPOCH 3 - PROGRESS: at 92.71% examples, 461392 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:06,679 : INFO : EPOCH 3 - PROGRESS: at 98.78% examples, 460830 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:06,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-27 10:30:06,849 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 10:30:06,854 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 10:30:06,856 : INFO : EPOCH - 3 : training on 9860127 raw words (7556250 effective words) took 16.4s, 460984 effective words/s\n",
      "2018-06-27 10:30:07,867 : INFO : EPOCH 4 - PROGRESS: at 5.88% examples, 442210 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:08,890 : INFO : EPOCH 4 - PROGRESS: at 12.26% examples, 458124 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:09,923 : INFO : EPOCH 4 - PROGRESS: at 18.74% examples, 464029 words/s, in_qsize 4, out_qsize 1\n",
      "2018-06-27 10:30:10,926 : INFO : EPOCH 4 - PROGRESS: at 24.62% examples, 459061 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:30:11,944 : INFO : EPOCH 4 - PROGRESS: at 30.80% examples, 459273 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:12,954 : INFO : EPOCH 4 - PROGRESS: at 37.18% examples, 462609 words/s, in_qsize 4, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-27 10:30:13,964 : INFO : EPOCH 4 - PROGRESS: at 43.67% examples, 466265 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:14,979 : INFO : EPOCH 4 - PROGRESS: at 50.05% examples, 467598 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:15,988 : INFO : EPOCH 4 - PROGRESS: at 56.13% examples, 466508 words/s, in_qsize 4, out_qsize 1\n",
      "2018-06-27 10:30:16,994 : INFO : EPOCH 4 - PROGRESS: at 62.21% examples, 465576 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:18,019 : INFO : EPOCH 4 - PROGRESS: at 68.19% examples, 462953 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:19,026 : INFO : EPOCH 4 - PROGRESS: at 74.77% examples, 464691 words/s, in_qsize 4, out_qsize 0\n",
      "2018-06-27 10:30:20,045 : INFO : EPOCH 4 - PROGRESS: at 81.05% examples, 464935 words/s, in_qsize 4, out_qsize 1\n",
      "2018-06-27 10:30:21,049 : INFO : EPOCH 4 - PROGRESS: at 87.54% examples, 466650 words/s, in_qsize 4, out_qsize 1\n",
      "2018-06-27 10:30:22,069 : INFO : EPOCH 4 - PROGRESS: at 94.02% examples, 467601 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:30:22,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-27 10:30:22,936 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 10:30:22,952 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 10:30:22,954 : INFO : EPOCH - 4 : training on 9860127 raw words (7555779 effective words) took 16.1s, 469465 effective words/s\n",
      "2018-06-27 10:30:23,967 : INFO : EPOCH 5 - PROGRESS: at 6.08% examples, 457922 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:24,968 : INFO : EPOCH 5 - PROGRESS: at 12.66% examples, 479047 words/s, in_qsize 4, out_qsize 0\n",
      "2018-06-27 10:30:25,975 : INFO : EPOCH 5 - PROGRESS: at 18.84% examples, 474181 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:26,986 : INFO : EPOCH 5 - PROGRESS: at 25.33% examples, 477280 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:28,006 : INFO : EPOCH 5 - PROGRESS: at 31.81% examples, 478283 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:29,031 : INFO : EPOCH 5 - PROGRESS: at 38.10% examples, 476100 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:30,032 : INFO : EPOCH 5 - PROGRESS: at 44.38% examples, 476127 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:31,054 : INFO : EPOCH 5 - PROGRESS: at 50.96% examples, 477713 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:32,064 : INFO : EPOCH 5 - PROGRESS: at 57.14% examples, 476329 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:30:33,064 : INFO : EPOCH 5 - PROGRESS: at 63.63% examples, 477743 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:34,067 : INFO : EPOCH 5 - PROGRESS: at 69.81% examples, 476113 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:35,087 : INFO : EPOCH 5 - PROGRESS: at 75.99% examples, 473925 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:36,092 : INFO : EPOCH 5 - PROGRESS: at 82.37% examples, 474515 words/s, in_qsize 5, out_qsize 1\n",
      "2018-06-27 10:30:37,102 : INFO : EPOCH 5 - PROGRESS: at 88.86% examples, 475388 words/s, in_qsize 6, out_qsize 0\n",
      "2018-06-27 10:30:38,102 : INFO : EPOCH 5 - PROGRESS: at 95.34% examples, 476356 words/s, in_qsize 5, out_qsize 0\n",
      "2018-06-27 10:30:38,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-06-27 10:30:38,780 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-06-27 10:30:38,793 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-06-27 10:30:38,794 : INFO : EPOCH - 5 : training on 9860127 raw words (7557597 effective words) took 15.8s, 477305 effective words/s\n",
      "2018-06-27 10:30:38,796 : INFO : training on a 49300635 raw words (37784103 effective words) took 80.1s, 471978 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# 主程序\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "sentences = word2vec.Text8Corpus(u\"CommentsCorpus627.txt\")  # 加载语料\n",
    "model = word2vec.Word2Vec(sentences, size=200)  # 默认window=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【不错】和【好】的相似度为： 0.4115686978519649\n"
     ]
    }
   ],
   "source": [
    "# 计算两个词的相似度/相关程度\n",
    "y1 = model.wv.similarity(u\"不错\", u\"好\")\n",
    "print (u\"【不错】和【好】的相似度为：\", y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和【恐怖】最相关的词有：\n",
      "\n",
      "惊悚 0.7792297601699829\n",
      "吓人 0.7512961626052856\n",
      "悬疑 0.5833338499069214\n",
      "新鲜 0.5731831789016724\n",
      "血腥 0.5706448554992676\n",
      "恐怖片 0.5642134547233582\n",
      "好看 0.560590386390686\n",
      "刺激 0.5362963676452637\n",
      "科幻 0.5329737067222595\n",
      "猎奇 0.5307242274284363\n",
      "好笑 0.5145022869110107\n",
      "爽快 0.5077004432678223\n",
      "紧张 0.5068250894546509\n",
      "新奇 0.5027656555175781\n",
      "惊吓 0.49789971113204956\n",
      "情色 0.4957892894744873\n",
      "鬼片 0.4923126697540283\n",
      "恶心 0.4886699914932251\n",
      "推理 0.4780545234680176\n",
      "高明 0.47662848234176636\n"
     ]
    }
   ],
   "source": [
    "# 计算某个词的相关词列表\n",
    "y2 = model.wv.most_similar(u\"恐怖\", topn=20)  # 20个最相关的\n",
    "print (u\"和【恐怖】最相关的词有：\\n\")\n",
    "for item in y2:\n",
    "    print (item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "书-不错，质量-\n",
      "中规中矩 0.5947837829589844\n",
      "值得一看 0.5882759094238281\n",
      "上乘 0.5812821984291077\n"
     ]
    }
   ],
   "source": [
    "# 寻找对应关系\n",
    "print (\"书-不错，质量-\")\n",
    "y3 = model.wv.most_similar([u'质量', u'不错'], [u'书'], topn=3)\n",
    "for item in y3:\n",
    "    print (item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不合群的词： 很\n"
     ]
    }
   ],
   "source": [
    "# 寻找不合群的词\n",
    "y4 = model.wv.doesnt_match(u\"书 书籍 教材 很\".split())\n",
    "print (u\"不合群的词：\", y4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-27 10:35:13,410 : INFO : saving Word2Vec object under CommentsW2V627.model, separately None\n",
      "2018-06-27 10:35:13,412 : INFO : storing np array 'vectors' to CommentsW2V627.model.wv.vectors.npy\n",
      "2018-06-27 10:35:13,568 : INFO : not storing attribute vectors_norm\n",
      "2018-06-27 10:35:13,570 : INFO : storing np array 'syn1neg' to CommentsW2V627.model.trainables.syn1neg.npy\n",
      "2018-06-27 10:35:13,739 : INFO : not storing attribute cum_table\n",
      "2018-06-27 10:35:13,947 : INFO : saved CommentsW2V627.model\n"
     ]
    }
   ],
   "source": [
    "# 保存模型，以便重用\n",
    "model.save(u\"CommentsW2V.model\")\n",
    "# 对应的加载方式\n",
    "# model_2 = word2vec.Word2Vec.load(\"text8.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
